\documentclass[a4paper, 11pt]{article}
\usepackage{comment} % enables the use of multi-line comments (\ifx \fi) 
\usepackage{lipsum} %This package just generates Lorem Ipsum filler text. 
\usepackage{fullpage} % changes the margin
\usepackage{amsmath, amssymb,graphicx, subcaption}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\begin{document}
%Header-Make sure you update this information!!!!
\section*{Problem-Statement}
Let an object have a reflectance given by $r$. Then the complex-distribution of the object-field is given by $g\sim CN(0,D(r))$ \cite{CaseyOpticallyCoherent}. The problem statement is given 
\begin{eqnarray*}
y=Ag+w
\end{eqnarray*}
we would like to estimate $r$.
\section{Case I: Linear measurements $(A=I)$}
\subsection{Forward-model: }
Let the reflectance of the object that is imaged be given by $r\in[0,1]$. Under the assumed model of the object-filed given by $g\sim CN(0,D(r))$, and the additive white-gaussian noise model we have that the measured complex-signal is given as 
\begin{eqnarray*}
y=g+w.
\end{eqnarray*}
A single-realization of this is given in Figure~\label{fig:forwardModel} with std. deviations of the noise at $\sigma_w=\{0.001,0.1\}$. 
\begin{figure}[h]
\centering
\centering
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{../Figures/OpticalReflectance.png}
        \caption{Reflectance ($r$)}
        \label{fig:reflectanceObject}
    \end{subfigure}
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{../Figures/ComplexOpticalFieldAmplitude.png}
        \caption{Optical-Field ($|g|$)}
        \label{fig:opticalField}
    \end{subfigure}
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{../Figures/NoisyMeasurementAmplitudeNoiseSigma1e-3.png}
        \caption{($|y|$) $\sigma=0.001$}
        \label{fig:noisyMeasurement1e-2}
    \end{subfigure}
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{../Figures/NoisyMeasurementAmplitudeNoiseSigma1e-1.png}
        \caption{($|y|$) $\sigma=0.1$}
        \label{fig:noisyMeasurement1e-1}
    \end{subfigure}
\caption{An example-realization of the forward-model $y=g+w$ . Two realizations of the noisy observations are shown at std. deviations of $\{0.001, 0.1\}$.}
\label{fig:forwardModel}
\end{figure}

\subsection{ML-estimate}
The likelihood of the measurements $y$ is given as $p(y|r)\sim CN(0,D(r)+\sigma_w^2I)$. Applying the maximum-likelihood estimator to the above problem we have  
\begin{eqnarray*}
\hat{r}&=& \argmax \log p(y|r) \\
&=& \argmax \frac{-1}{2} \Bigg( \log\left( (2\pi)^N|D(r)+\sigma_w^2I|\right)+y^H (D(r)+\sigma_w^2I)^{-1}y\Bigg) \\
&=& \argmax \frac{-1}{2} \Bigg( \sum_{i=1}^N \log \left( 2\pi (r_i +\sigma_w ^2)\right) +\frac{|y_i|^2}{r_i +\sigma_w^2}\Bigg) \\
\implies \hat{r_i}&=& \argmax \frac{-1}{2} \Bigg( \log \left( 2\pi (r_i +\sigma_w ^2)\right) +\frac{|y_i|^2}{r_i +\sigma_w^2} \Bigg) \\
&=& \argmin \log \left( 2\pi (r_i +\sigma_w ^2)\right) +\frac{|y_i|^2}{r_i +\sigma_w^2}.
\end{eqnarray*}
Taking the differential of the above equation and equating to zero we get the ML estimate   
\begin{eqnarray*}
\hat{r}_i&=&|y_i|^2-\sigma_w^2.
\end{eqnarray*}
The reconstructions for varying degrees of noise is shown in Figure~\ref{fig:inversionModel} (a-d). 
\begin{figure}[h]
\centering
\centering
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{../Figures/MLReconstructionNoiseSigma1e-2.png}
        \caption{\tiny ML ($\sigma_w=1e^{-2}$)}
        \label{fig:ML-2}
    \end{subfigure}
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{../Figures/MLReconstructionNoiseSigma1e-1.png}
        \caption{\tiny ML ($\sigma_w=1e^{-1}$)}
        \label{fig:ML-1}
    \end{subfigure}
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{../Figures/MLReconstructionNoiseSigma1e0.png}
        \caption{\tiny ML ($\sigma_w=1e^{0}$)}
        \label{fig:ML0}
    \end{subfigure}
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{../Figures/MLReconstructionNoiseSigma1e1.png}
        \caption{\tiny ML ($\sigma_w=1e^{1}$)}
        \label{fig:ML1}
    \end{subfigure}
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{../Figures/PnPReconstructionNoiseSigma1e-4.png}
        \caption{\tiny PnP-TV ($\sigma_w=1e^{-4}$)}
        \label{fig:PnP-2}
    \end{subfigure}
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{../Figures/PnPReconstructionNoiseSigma1e-3.png}
        \caption{\tiny PnP-TV ($\sigma_w=1e^{-3}$)}
        \label{fig:PnP-1}
    \end{subfigure}
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{../Figures/PnPReconstructionNoiseSigma1e-2.png}
        \caption{\tiny PnP-TV ($\sigma_w=1e^{-2}$)}
        \label{fig:PnP0}
    \end{subfigure}
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{../Figures/PnPReconstructionNoiseSigma1e-1.png}
        \caption{\tiny PnP-TV ($\sigma_w=1e^{-1}$)}
        \label{fig:PnP1}
    \end{subfigure}
\caption{An example-realization for different inversion-models. The inversions are shown for different std. deviations of $\{1e^{-4},1e^{-3}, 1e^{-2},1e^{-1}\}$.}
\label{fig:inversionModel}
\end{figure}
\begin{figure}[h]
\centering
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{../Figures/MLReconstructionNoiseSigma1e-3Realization3.png}
        \caption{ML ($N=3$)}
        \label{fig:MLN1}
    \end{subfigure}
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{../Figures/MLReconstructionNoiseSigma1e-3Realization6.png}
        \caption{ML ($N=6$)}
        \label{fig:MLN3}
    \end{subfigure}
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{../Figures/MLReconstructionNoiseSigma1e-3Realization20.png}
        \caption{ML ($N=20$)}
        \label{fig:MLN20}
    \end{subfigure}
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{../Figures/MLReconstructionNoiseSigma1e-3Realization20.png}
        \caption{ML ($N=40$)}
        \label{fig:MLN40}
    \end{subfigure}

\begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{../Figures/PnPReconstructionNoiseSigma1e-3Realization3.png}
        \caption{PnP-TV ($N=3$)}
        \label{fig:PnP-2}
    \end{subfigure}
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{../Figures/PnPReconstructionNoiseSigma1e-3Realization6.png}
        \caption{PnP-TV ($N=6$)}
        \label{fig:PnP-1}
    \end{subfigure}
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{../Figures/PnPReconstructionNoiseSigma1e-3Realization20.png}
        \caption{PnP-TV ($N=20$)}
        \label{fig:PnP0}
    \end{subfigure}
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{../Figures/PnPReconstructionNoiseSigma1e-3Realization20.png}
        \caption{PnP-TV ($N=40$)}
        \label{fig:PnP1}
    \end{subfigure}
\caption{Multi-image plug and play algorithm for: For the image with $\sigma_w=1e^{-3}$  .}
\label{fig:inversionModel}
\end{figure}
\subsection{Plug and play (PnP) estimate (MAP)}
The MAP estiamate for the above problem is given as 
\begin{eqnarray}
\hat{r}&=& \argmin -\log p(r|y) \notag\\
&=& \argmin  -\log p(y|r)-\log p(r). \label{eq:MAPestimate}
\end{eqnarray}
The PnP algorithm \cite{PnPalgorithm} decouples the above problem into one where we can apply the forward and prior models in the form of denoisers. Specifically, the PnP algorithm operates by splitting the unknown variable $r$ into two variables $r,v$ and converts the unconstrained optimization problem in (\ref{eq:MAPestimate}) into a constrained optimization problem 
\begin{eqnarray} 
\hat{r}=\underset{r=v}{\argmin} \,\, \ell (r)+\beta s(v)
\end{eqnarray}
where $\beta s(v)=p(v)$ is the prior term and $\ell (r)$ enforces the meausrement constraints on $r$. Adopting an ADMM approach to solve the above problem results in an algorithm containing two primary operations:\\ \\(1) \textbf{Inversion operator} 
\begin{eqnarray*}
F(\tilde{r},\sigma_\lambda)=\underset{r}{\argmin} \left \{ \ell(r)+\frac{1}{2\sigma_\lambda^2} \|r-\tilde{r}\|^2 \right \}, 
\end{eqnarray*}
 where $\tilde{r}=v-u$. The operator $F$ is the proximal mapping of $\ell(r)$ and is equivalent to a MAP estimate of $r$ with a Gaussian prior having a distribution $p(r)\sim N(\tilde{r},\sigma_\lambda^2I)$. \\
Specifically when $\ell(r)=-\log p(y|r)$, the inversion operator is given as 
\begin{eqnarray*}
F(\tilde{r_i},\sigma_\lambda)&=&\underset{r_i}{\argmin} \left \{ \log (r_i+\sigma_w^2)+\frac{|y_i|^2}{r_i+\sigma_w^2}+\frac{1}{2\sigma_\lambda^2} (r_i-\tilde{r_i})^2 \right \}, \\
&\implies&  \frac{1}{r_i+\sigma_w^2}-\frac{|y_i|^2}{(r_i+\sigma_w^2)^2}+\frac{1}{\sigma_\lambda^2} (r_i-\tilde{r_i}) =0, \\
&\implies&  \sigma_\lambda^2(r_i+\sigma_w^2)-|y_i|^2+(r_i-\tilde{r_i})(r_i+\sigma_w^2)^2 =0, \\
&\implies&  r_i^3+(-\tilde{r}_i+2\sigma_w^2)r_i^2+(-2\tilde{r}_{i}\sigma_w^2+\sigma_w^4+\sigma_\lambda^2)r_i+(\sigma_\lambda^2\sigma_w^2-\tilde{r}_i\sigma_w^4 )=0. \\
\end{eqnarray*}
Thus the solution of the inversion-operator is simply the root of the cubic-polynomial. We are constrained that the root of the cubic-polynomial is real.  \\ \\
(2) \textbf{Denoising operator} 
\begin{eqnarray*}
H(\tilde{v},\sigma_n)=\underset{v}{\argmin} \left \{ \frac{1}{2\sigma_n^2} \|v-\tilde{v}\|^2 +s(v)\right \} 
\end{eqnarray*}
where $\sigma_n^2=\beta \sigma_\lambda^2$ and $\tilde{v}=r+u$. The denosing operator $H$ is a proximal mapping of $s(v)$. Mathematically, it is equivalent to a Gaussian denosing operation. Thus, we can replace $H$ with a denoiser which removes noise with a variance $\sigma_n^2$. We use the following denoising-operators to use for Gaussian-denosing: (1) TV, (2) BM3D denoiser. The complete PnP algorithm is given in Algorithm~\ref{alg:PnP}. 

\begin{algorithm}
\caption{Plug and Play ($y, \sigma_w,\sigma_\lambda,\sigma_n$)}\label{euclid}
\begin{algorithmic}[1]
\State $v=y$, $u=0$
\State Repeat 
\State \{
\State $\tilde{r}=v-u$
\State $r=F(y,\tilde{r},\sigma_w,\sigma_\lambda)$ \quad \textbf{Inversion-Operator}
\State $\tilde{v}=r+u$
\State $v=H(\tilde{v},\sigma_n)$ \quad \textbf{Denoising-Operator}
\State $u=u+(r-v)$
\State \}
\end{algorithmic}
\label{alg:PnP}
\end{algorithm}
\subsubsection{Parameter-tuning}
In the following analysis we assume that we know the true-value of $\sigma_w$. The parameters to be tuned for the problem are $\sigma_\lambda, \sigma_n$; which are essentially the tuning parameters for each of the proximal-operators (inversion and denoising). 
\clearpage 
\newpage 
\subsection{Direct CNN-approach}
Recently we have tried another direct CNN approach to directly learn the mapping from $|y|$ to $r$. In this approach we learn the mapping from $|y|$ to $r$ by training a convolutional neural network (CNN) on the image pairs from the phase-less measurements to the reflectance of the object. The network architecture that we use follows from the network that has been used for the perceptual-loss extraction paper in SRNET \cite{SRNET}. \\
The architecture that we used is outlined in Tables~\ref{networkArch}. A residual and convolution block is shown in Figures~\ref{residualConvBlock}. The results of using testing the trained CNN on the test data is shown in Figure~\ref{fig:outputFig}. An evaluation of the hyperparameter of the learning rate is shown in Figure~\ref{fig:learningRate}. We note the variation of the training error as the learning-rate parameter is changed in the experiments. The multi-image results with the trained CNN is shown in Figure~\ref{fig:avgFig}. This figure indicates that it is performing better in comparison to the approach of the plug and play approach used with the EM algorithm. 

\begin{minipage}{\textwidth}
  \begin{minipage}[b]{0.45\textwidth}
    \centering
\includegraphics[width=0.8\textwidth]{../Figures/residualConvBlock.pdf}
    \captionof{figure}{A sample residual and conolutional block.}
  \label{residualConvBlock}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.45\textwidth}
    \centering
\includegraphics[width=0.8\textwidth]{/mnt/temp/data/coherentImageFormation/results/learning_rate_comparison.pdf}
    \captionof{figure}{A comparison of training errors for different learning-rates.}
  \label{fig:learningRate}
  \end{minipage}
  \end{minipage}
\begin{table}[h]
\centering
\begin{tabular}{ | c | c |}
    \hline
    Layer & Activation-size  \\ \hline
    Input & $3\times 224 \times 224$  \\ \hline
    $64 \times 9\times 9$ convBlock & $64 \times 224 \times 224$  \\ \hline
    Residual block $64$ filters& $64 \times 224 \times 224$  \\ \hline
    Residual block $64$ filters& $64 \times 224 \times 224$  \\ \hline
    Residual block $64$ filters& $64 \times 224 \times 224$  \\ \hline
    Residual block $64$ filters& $64 \times 224 \times 224$  \\ \hline
    $64 \times 3 \times 3$ convBlock & $64 \times 224 \times 224$  \\ \hline
    $3 \times 9\times 9$ conv2d & $3 \times 224 \times 224$  \\ \hline
    batchNormalization & $3$  \\ \hline
    \end{tabular}
      \captionof{table}{Network architecture used for the direct CNN based reflectance retrieval.}
\label{networkArch}
\end{table}
\begin{figure}[!h]
\centering
\begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{/mnt/temp/data/coherentImageFormation/results/GT.png}
        \caption{GT}
        \label{fig:GT}
    \end{subfigure}
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{/mnt/temp/data/coherentImageFormation/results/inputImg.png}
        \caption{Input image}
        \label{fig:inputImg}
    \end{subfigure}
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{/mnt/temp/data/coherentImageFormation/results/outputImg.png}
        \caption{Output-Img}
        \label{fig:outputImg}
    \end{subfigure}
\caption{The learning-rate used to define this network is $0.01$ with a step-decay parameter of $0.1$ and a step-list being $[10, 25]$. The number of training-epochs is $100$.}
\label{fig:outputFig}
\end{figure}

\begin{figure}[!h]
\centering
\begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{/mnt/temp/data/coherentImageFormation/results/GT1.png}
        \caption{GT}
        \label{fig:GT}
    \end{subfigure}
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{/mnt/temp/data/coherentImageFormation/results/inputImg1.png}
        \caption{Input image}
        \label{fig:inputImg}
    \end{subfigure}
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{/mnt/temp/data/coherentImageFormation/results/outputImg1.png}
        \caption{Output-Img}
        \label{fig:outputImg}
    \end{subfigure}
\caption{The learning-rate used to define this network is $0.01$ with a step-decay parameter of $0.1$ and a step-list being $[10, 25]$. The number of training-epochs is $100$. We use a deeper-architecture in comparison to the SRNET architecture.}
\label{fig:outputFig}
\end{figure}

\begin{figure}[!h]
\centering
\begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{/mnt/temp/data/coherentImageFormation/results/avg1.png}
        \caption{$N = 1$}
        \label{fig:avg1}
    \end{subfigure}
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{/mnt/temp/data/coherentImageFormation/results/avg3.png}
        \caption{$N = 3$}
        \label{fig:avg3}
    \end{subfigure}
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{/mnt/temp/data/coherentImageFormation/results/avg6.png}
        \caption{$N = 6$}
        \label{fig:avg6}
    \end{subfigure}
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{/mnt/temp/data/coherentImageFormation/results/avg20.png}
        \caption{$N = 20$}
        \label{fig:avg20}
    \end{subfigure}
\caption{Multi-image CNN algorithm for: For the image with $\sigma_w=1e^{-3}$.}
\label{fig:avgFig}
\end{figure}
\clearpage 
\newpage 
\subsection{Regularization by denoising}
Recently there has been an alternative approach instead of the ADMM or Plug-and-Play ($P^3$) approach: regularization by denoising \cite{RED}. The key idea of the paper is the regularization proposed in the paper:
\begin{eqnarray*}
\rho(x)=\frac{1}{2}x^T[x-f(x)],  
\end{eqnarray*}
where $f(x)$ is the denosied version of $x$. The intuition behind this regulaization is:
\begin{itemize}
\item Penalty introduced is the inner-product between the candidate image $x$ and its denosing residual. 
\end{itemize}
A small value for $\rho(x)$ implies that 
\begin{itemize}
\item Residual is very small, image $x$ is at the fixed point or $x\approx f(x)$. 
\item Cross-correlation between the image $x$ and its residual is very small or alternatively resembles white-noise or contains no image-like features. 
\end{itemize}
\subsection{Properties of the denosier $f(x)$}
The RED paper assumes that a denoiser can be assumed to be a psuedo-linear filter of the form 
\begin{eqnarray*}
f(x)=W(x)x. 
\end{eqnarray*}
The following properties are further assumed on the denoiser (\textbf{to be completed}).
\subsection{Solving the regularized optimization problem}
A general inverse-problem is of the form 
\begin{eqnarray*}
\hat{x}=\underset{x}{\argmin} \quad E(x) \triangleq \ell(x,y)+\frac{\lambda}{2}x^T[x-f(x)]. 
\end{eqnarray*}
The gradient of the above expression is of the form 
\begin{eqnarray*}
\nabla_xE(x)&=&\nabla_x\ell(y,x)+\frac{\lambda}{2}\nabla_x\{x^T(x-f(x))\} \\
&=&\nabla_x\ell(y,x)+\lambda(x-f(x)). 
\end{eqnarray*}
With the above formulation, a gradient-descent based iterative approach would consist of the following iterations:
\begin{eqnarray*}
\hat{x}_{k+1}=\hat{x}_k-\mu \nabla_xE(x)|_{\hat{x}_k}. 
\end{eqnarray*}
\subsection{Regularization by denoising for reflectance-estimation }
The regularization by denoising approach for the reflectance-reconstruction problem is given as 
\begin{eqnarray*}
\hat{r}&=&\underset{r}{\argmin} \quad \ell(r,y)+\lambda \rho(r) \\
&=& \underset{r}{\argmin} \quad \sum_{i=1}^N \left(\log (2\pi (r_i+\sigma_w^2))+\frac{|y_i|^2}{r_i+\sigma_w^2}\right) + \frac{\lambda}{2} r^T\{r-f(r)\} \\
&=&  \underset{r}{\argmin} \quad E(r). 
\end{eqnarray*}
The RED algorithm for using this procedure is of the form 
\begin{eqnarray*}
\hat{r}_{k+1}=\hat{r}_k-\mu \nabla_rE(r)|_{\hat{r}_k}, 
\end{eqnarray*}
where 
\begin{eqnarray*}
\nabla_rE(r)&=& \left(\sum_{i=1}^N \frac{1}{2\pi(r_i+\sigma_w^2)}-\frac{|y_i|^2}{(r_i+\sigma_w^2)^2}\right)+\lambda(r-f(r)). 
\end{eqnarray*}

\begin{thebibliography}{9}
\bibitem{CaseyOpticallyCoherent} Casey J. Pellizzari et al. \emph{Optically coherent image formation and denoising using a plug and play inversion framework in OSA}.
\bibitem{PnPalgorithm} S.~V.~Venkatakrishnan et al. \emph{Plug-and-play priors for model based reconstruction in GLOBALSIP}.
\bibitem{RED} Y.~Romano et al. \emph{The little engine that could: Regularization by denoising}.
\bibitem{SRNET} J.~Johnson et al. \emph{Perceptual Losses for Real-Time Style Transfer and Super-Resolution}.
\end{thebibliography}

\end{document}
