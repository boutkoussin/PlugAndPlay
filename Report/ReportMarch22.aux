\relax 
\citation{CaseyOpticallyCoherent}
\@writefile{toc}{\contentsline {section}{\numberline {1}Case I: Linear measurements $(A=I)$}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Forward-model: }{1}}
\newlabel{fig:forwardModel}{{1.1}{1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:reflectanceObject}{{1a}{1}}
\newlabel{sub@fig:reflectanceObject}{{a}{1}}
\newlabel{fig:opticalField}{{1b}{1}}
\newlabel{sub@fig:opticalField}{{b}{1}}
\newlabel{fig:noisyMeasurement1e-2}{{1c}{1}}
\newlabel{sub@fig:noisyMeasurement1e-2}{{c}{1}}
\newlabel{fig:noisyMeasurement1e-1}{{1d}{1}}
\newlabel{sub@fig:noisyMeasurement1e-1}{{d}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces An example-realization of the forward-model $y=g+w$ . Two realizations of the noisy observations are shown at std. deviations of $\{0.001, 0.1\}$.\relax }}{1}}
\newlabel{fig:forwardModel}{{1}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}ML-estimate}{1}}
\citation{PnPalgorithm}
\newlabel{fig:ML-2}{{2a}{2}}
\newlabel{sub@fig:ML-2}{{a}{2}}
\newlabel{fig:ML-1}{{2b}{2}}
\newlabel{sub@fig:ML-1}{{b}{2}}
\newlabel{fig:ML0}{{2c}{2}}
\newlabel{sub@fig:ML0}{{c}{2}}
\newlabel{fig:ML1}{{2d}{2}}
\newlabel{sub@fig:ML1}{{d}{2}}
\newlabel{fig:PnP-2}{{2e}{2}}
\newlabel{sub@fig:PnP-2}{{e}{2}}
\newlabel{fig:PnP-1}{{2f}{2}}
\newlabel{sub@fig:PnP-1}{{f}{2}}
\newlabel{fig:PnP0}{{2g}{2}}
\newlabel{sub@fig:PnP0}{{g}{2}}
\newlabel{fig:PnP1}{{2h}{2}}
\newlabel{sub@fig:PnP1}{{h}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces An example-realization for different inversion-models. The inversions are shown for different std. deviations of $\{1e^{-4},1e^{-3}, 1e^{-2},1e^{-1}\}$.\relax }}{2}}
\newlabel{fig:inversionModel}{{2}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Plug and play (PnP) estimate (MAP)}{2}}
\newlabel{eq:MAPestimate}{{1}{2}}
\newlabel{fig:MLN1}{{3a}{3}}
\newlabel{sub@fig:MLN1}{{a}{3}}
\newlabel{fig:MLN3}{{3b}{3}}
\newlabel{sub@fig:MLN3}{{b}{3}}
\newlabel{fig:MLN20}{{3c}{3}}
\newlabel{sub@fig:MLN20}{{c}{3}}
\newlabel{fig:MLN40}{{3d}{3}}
\newlabel{sub@fig:MLN40}{{d}{3}}
\newlabel{fig:PnP-2}{{3e}{3}}
\newlabel{sub@fig:PnP-2}{{e}{3}}
\newlabel{fig:PnP-1}{{3f}{3}}
\newlabel{sub@fig:PnP-1}{{f}{3}}
\newlabel{fig:PnP0}{{3g}{3}}
\newlabel{sub@fig:PnP0}{{g}{3}}
\newlabel{fig:PnP1}{{3h}{3}}
\newlabel{sub@fig:PnP1}{{h}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Multi-image plug and play algorithm for: For the image with $\sigma _w=1e^{-3}$ .\relax }}{3}}
\newlabel{fig:inversionModel}{{3}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.1}Parameter-tuning}{3}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Plug and Play ($y, \sigma _w,\sigma _\lambda ,\sigma _n$)\relax }}{4}}
\newlabel{euclid}{{1}{4}}
\newlabel{alg:PnP}{{1}{4}}
\citation{SRNET}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Direct CNN-approach}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces A sample residual and conolutional block.\relax }}{5}}
\newlabel{residualConvBlock}{{4}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces A comparison of training errors for different learning-rates.\relax }}{5}}
\newlabel{fig:learningRate}{{5}{5}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Network architecture used for the direct CNN based reflectance retrieval.\relax }}{5}}
\newlabel{networkArch}{{1}{5}}
\newlabel{fig:GT}{{6a}{6}}
\newlabel{sub@fig:GT}{{a}{6}}
\newlabel{fig:inputImg}{{6b}{6}}
\newlabel{sub@fig:inputImg}{{b}{6}}
\newlabel{fig:outputImg}{{6c}{6}}
\newlabel{sub@fig:outputImg}{{c}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The learning-rate used to define this network is $0.01$ with a step-decay parameter of $0.1$ and a step-list being $[10, 25]$. The number of training-epochs is $100$.\relax }}{6}}
\newlabel{fig:outputFig}{{6}{6}}
\newlabel{fig:GT}{{7a}{6}}
\newlabel{sub@fig:GT}{{a}{6}}
\newlabel{fig:inputImg}{{7b}{6}}
\newlabel{sub@fig:inputImg}{{b}{6}}
\newlabel{fig:outputImg}{{7c}{6}}
\newlabel{sub@fig:outputImg}{{c}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces The learning-rate used to define this network is $0.01$ with a step-decay parameter of $0.1$ and a step-list being $[10, 25]$. The number of training-epochs is $100$. We use a deeper-architecture in comparison to the SRNET architecture.\relax }}{6}}
\newlabel{fig:outputFig}{{7}{6}}
\newlabel{fig:avg1}{{8a}{6}}
\newlabel{sub@fig:avg1}{{a}{6}}
\newlabel{fig:avg3}{{8b}{6}}
\newlabel{sub@fig:avg3}{{b}{6}}
\newlabel{fig:avg6}{{8c}{6}}
\newlabel{sub@fig:avg6}{{c}{6}}
\newlabel{fig:avg20}{{8d}{6}}
\newlabel{sub@fig:avg20}{{d}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Multi-image CNN algorithm for: For the image with $\sigma _w=1e^{-3}$.\relax }}{6}}
\newlabel{fig:avgFig}{{8}{6}}
\citation{RED}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Regularization by denoising}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6}Properties of the denosier $f(x)$}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7}Solving the regularized optimization problem}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8}Regularization by denoising for reflectance-estimation }{7}}
\bibcite{CaseyOpticallyCoherent}{1}
\bibcite{PnPalgorithm}{2}
\bibcite{RED}{3}
\bibcite{SRNET}{4}
