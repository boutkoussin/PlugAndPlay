\relax 
\citation{CaseyOpticallyCoherent}
\@writefile{toc}{\contentsline {section}{\numberline {1}Case I: Linear measurements $(A=I)$}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Forward-model: }{1}}
\newlabel{fig:forwardModel}{{1.1}{1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:reflectanceObject}{{1a}{1}}
\newlabel{sub@fig:reflectanceObject}{{a}{1}}
\newlabel{fig:opticalField}{{1b}{1}}
\newlabel{sub@fig:opticalField}{{b}{1}}
\newlabel{fig:noisyMeasurement1e-2}{{1c}{1}}
\newlabel{sub@fig:noisyMeasurement1e-2}{{c}{1}}
\newlabel{fig:noisyMeasurement1e-1}{{1d}{1}}
\newlabel{sub@fig:noisyMeasurement1e-1}{{d}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces An example-realization of the forward-model $y=g+w$ . Two realizations of the noisy observations are shown at std. deviations of $\{0.001, 0.1\}$.\relax }}{1}}
\newlabel{fig:forwardModel}{{1}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}ML-estimate}{1}}
\citation{PnPalgorithm}
\newlabel{fig:ML-2}{{2a}{2}}
\newlabel{sub@fig:ML-2}{{a}{2}}
\newlabel{fig:ML-1}{{2b}{2}}
\newlabel{sub@fig:ML-1}{{b}{2}}
\newlabel{fig:ML0}{{2c}{2}}
\newlabel{sub@fig:ML0}{{c}{2}}
\newlabel{fig:ML1}{{2d}{2}}
\newlabel{sub@fig:ML1}{{d}{2}}
\newlabel{fig:PnP-2}{{2e}{2}}
\newlabel{sub@fig:PnP-2}{{e}{2}}
\newlabel{fig:PnP-1}{{2f}{2}}
\newlabel{sub@fig:PnP-1}{{f}{2}}
\newlabel{fig:PnP0}{{2g}{2}}
\newlabel{sub@fig:PnP0}{{g}{2}}
\newlabel{fig:PnP1}{{2h}{2}}
\newlabel{sub@fig:PnP1}{{h}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces An example-realization for different inversion-models. The inversions are shown for different std. deviations of $\{1e^{-4},1e^{-3}, 1e^{-2},1e^{-1}\}$.\relax }}{2}}
\newlabel{fig:inversionModel}{{2}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Plug and play (PnP) estimate (MAP)}{2}}
\newlabel{eq:MAPestimate}{{1}{2}}
\newlabel{fig:MLN1}{{3a}{3}}
\newlabel{sub@fig:MLN1}{{a}{3}}
\newlabel{fig:MLN3}{{3b}{3}}
\newlabel{sub@fig:MLN3}{{b}{3}}
\newlabel{fig:MLN20}{{3c}{3}}
\newlabel{sub@fig:MLN20}{{c}{3}}
\newlabel{fig:MLN40}{{3d}{3}}
\newlabel{sub@fig:MLN40}{{d}{3}}
\newlabel{fig:PnP-2}{{3e}{3}}
\newlabel{sub@fig:PnP-2}{{e}{3}}
\newlabel{fig:PnP-1}{{3f}{3}}
\newlabel{sub@fig:PnP-1}{{f}{3}}
\newlabel{fig:PnP0}{{3g}{3}}
\newlabel{sub@fig:PnP0}{{g}{3}}
\newlabel{fig:PnP1}{{3h}{3}}
\newlabel{sub@fig:PnP1}{{h}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Multi-image plug and play algorithm for: For the image with $\sigma _w=1e^{-3}$ .\relax }}{3}}
\newlabel{fig:inversionModel}{{3}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.1}Parameter-tuning}{3}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Plug and Play ($y, \sigma _w,\sigma _\lambda ,\sigma _n$)\relax }}{4}}
\newlabel{euclid}{{1}{4}}
\newlabel{alg:PnP}{{1}{4}}
\citation{SRNET}
\citation{SRNET}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Direct CNN-approach}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces A sample residual and conolutional block.\relax }}{5}}
\newlabel{residualConvBlock}{{4}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces A comparison of training errors for different learning-rates.\relax }}{5}}
\newlabel{fig:learningRate}{{5}{5}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Network architecture used for the direct CNN based reflectance retrieval.\relax }}{5}}
\newlabel{networkArch}{{1}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.1}Perceptual loss-function}{5}}
\newlabel{fig:GT}{{6a}{6}}
\newlabel{sub@fig:GT}{{a}{6}}
\newlabel{fig:inputImg}{{6b}{6}}
\newlabel{sub@fig:inputImg}{{b}{6}}
\newlabel{fig:outputImg}{{6c}{6}}
\newlabel{sub@fig:outputImg}{{c}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The learning-rate used to define this network is $0.01$ with a step-decay parameter of $0.1$ and a step-list being $[10, 25]$. The number of training-epochs is $100$. We use a deeper-architecture in comparison to the SRNET architecture.\relax }}{6}}
\newlabel{fig:outputFig}{{6}{6}}
\newlabel{fig:avg1}{{7a}{6}}
\newlabel{sub@fig:avg1}{{a}{6}}
\newlabel{fig:avg3}{{7b}{6}}
\newlabel{sub@fig:avg3}{{b}{6}}
\newlabel{fig:avg6}{{7c}{6}}
\newlabel{sub@fig:avg6}{{c}{6}}
\newlabel{fig:avg20}{{7d}{6}}
\newlabel{sub@fig:avg20}{{d}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces CNN algorithm applied for multiple images: The noise in each of the images is $\sigma _w=1e^{-3}$.\relax }}{6}}
\newlabel{fig:avgFig}{{7}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Architecture of the image-classifier\relax }}{6}}
\newlabel{fig:ArchClassifier}{{8}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Comparison of perceptual loss and $\ell _2$ loss-function.\relax }}{7}}
\newlabel{fig:avg1}{{10a}{7}}
\newlabel{sub@fig:avg1}{{a}{7}}
\newlabel{fig:avg3}{{10b}{7}}
\newlabel{sub@fig:avg3}{{b}{7}}
\newlabel{fig:avg6}{{10c}{7}}
\newlabel{sub@fig:avg6}{{c}{7}}
\newlabel{fig:avg20}{{10d}{7}}
\newlabel{sub@fig:avg20}{{d}{7}}
\newlabel{fig:avg1}{{10e}{7}}
\newlabel{sub@fig:avg1}{{e}{7}}
\newlabel{fig:avg3}{{10f}{7}}
\newlabel{sub@fig:avg3}{{f}{7}}
\newlabel{fig:avg6}{{10g}{7}}
\newlabel{sub@fig:avg6}{{g}{7}}
\newlabel{fig:avg20}{{10h}{7}}
\newlabel{sub@fig:avg20}{{h}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces (a)-(d) Performance of the $\ell _2$ loss-classifier. (e)-(h) Performance of the $67\%$ accurate classifier. \relax }}{7}}
\newlabel{fig:avgFig}{{10}{7}}
\citation{RED}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Regularization by denoising}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6}Properties of the denosier $f(x)$}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7}Solving the regularized optimization problem}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8}Regularization by denoising for reflectance-estimation }{8}}
\bibcite{CaseyOpticallyCoherent}{1}
\bibcite{PnPalgorithm}{2}
\bibcite{RED}{3}
\bibcite{SRNET}{4}
